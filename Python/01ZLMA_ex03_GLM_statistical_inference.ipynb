{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleksejalex/01ZLMA_forked/blob/main/Python/01ZLMA_ex03_GLM_statistical_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-i6MbNFm4Zt"
      },
      "source": [
        "# 01ZLMA - Exercise 03\n",
        "Exercise 03 of the course 01ZLMA. \n",
        "\n",
        "## Contents\n",
        "\n",
        "* Statistical Inference\n",
        " ---\n",
        "* Testing\n",
        " ---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "593Mg4ZbbeEE"
      },
      "source": [
        "#  Necessary theory recap from Lecture 04\n",
        "\n",
        "Under the conditions of regularity holds\n",
        "\n",
        "1.  $ \\ U(\\beta) \\sim N_{p}(0,I(\\beta)) \\Rightarrow  I^{-\\frac{1}{2}}(\\beta)\\, U(\\beta) {\\stackrel{D}{\\longrightarrow}} N_{p}(0, 1)$\n",
        "2. $ U(\\beta)I^{-1}(\\beta)U(\\beta)\\sim \\chi^{2}(p) \\Rightarrow U(\\beta)^T I^{-1}(\\beta)U(\\beta)  {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
        "3. Consistency of $\\hat{\\beta}$ and Wald statistics: \\\\\n",
        " $\\hat{\\beta}\\sim N_{p}(\\beta,I^{-1}(\\beta)) \\Rightarrow\n",
        "(\\hat{\\beta}-\\beta)^T I(\\beta)(\\hat{\\beta}-\\beta) {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2c7jDIXSGGL"
      },
      "source": [
        "Saturated and null model\n",
        "\n",
        "* Null model: $\\mu_i = \\mu, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
        "The Null Model assumes one parameter for all of the data points, which means you only estimate 1 parameter. \n",
        "* Saturated model: $Y_i = \\hat{\\mu_i}, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
        "The Saturated Model is a model that assumes each data point has its own parameters, which means you have n parameters to estimate.\n",
        "* Proposed Model:  model, where you try to explain your data points with $p$ parameters + an intercept term, so you have p+1 parameters, where $1 \\leq p \\leq n$.\n",
        "\n",
        "Questions:\n",
        "* What is the difference between null and saturated model?\n",
        "* Which model has greater log-likelihoood value?\n",
        "* Which model has the highest log-likelihood value?\n",
        "* What can you say about asymptotic distributions of $\\hat{\\beta}$ and $U(\\hat{\\beta})$ for saturated model?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download custom library from GitHub\n",
        "(using `wget` library)"
      ],
      "metadata": {
        "id": "iOc0DcmFG5SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "url = \"https://github.com/francji1/01ZLMA/raw/main/Python/helpers.py\"\n",
        "wget.download(url, '../content/helpers.py')  # path working for Google Colab"
      ],
      "metadata": {
        "id": "24VpxJrXG34x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um9ho8cQHobx"
      },
      "source": [
        "## Let's code "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwHFMyUxOSqD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import sklearn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.graphics.api import abline_plot\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from helpers import DiagnosticPlots, Anova\n",
        "\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-kZTsg7FZoM"
      },
      "source": [
        "Use Example 2 from the last Exercise 02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fov4Z_w9OSqF"
      },
      "outputs": [],
      "source": [
        "n  = 20 # n observations\n",
        "m  = 2 # m parameters to estimate\n",
        "X1 = np.ones((n*m,))  # Intercept\n",
        "X2 = np.array([i for i in range(1, n+1)] * m) # Regressors\n",
        "X = np.vstack([X1, np.log(X2)]).T # design matrix\n",
        "beta = np.array([0.9, 1.3]) # Regression coefficients\n",
        "lamdas = np.exp(X @ beta) # Means\n",
        "Y = np.random.poisson(lamdas, n*m) # Response variable with Poisson distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU_eFKcbWMUy"
      },
      "outputs": [],
      "source": [
        "# to create models we can use standard api or formula (r-like) api in statsmodels\n",
        "# formula api requires dataset (pandas) and formula\n",
        "d = pd.DataFrame(data={'Y': Y, 'X1': X1, 'X2':X2})\n",
        "#model = smf.glm(formula='Y~np.log(X2)', data=d, family=sm.families.Poisson()).fit()\n",
        "\n",
        "# standard api requires specifying endog (response) and exog (explanatory) design matrices\n",
        "model = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
        "print(model.summary())\n",
        "\n",
        "beta_e = model.params; print(f'estimated params are:{beta_e}')\n",
        "y_hat = model.predict(); print(f'fitted values are:{y_hat}')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(X2, Y, color='red', marker='o')\n",
        "ax.plot(np.unique(y_hat), color='blue')\n",
        "ax.set_title('Poisson model')\n",
        "ax.set_xlabel('Year Quoter')\n",
        "ax.set_ylabel('Number of cases')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N8x-oi3HAKK"
      },
      "source": [
        "Repetition using custom function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSqY9UVsOSqG"
      },
      "outputs": [],
      "source": [
        "# function to calcualate weights W\n",
        "def calc_W_inv(X, beta):\n",
        "    return np.diag(np.exp(X @ beta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcA9wuh1WMtL"
      },
      "outputs": [],
      "source": [
        "# function to calcualate weights Z\n",
        "def calc_Z(X,Y,beta):\n",
        "    return X@beta + (Y - np.exp(X@beta)) / np.exp(X@beta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igkUvl36XAGV"
      },
      "outputs": [],
      "source": [
        "# IWLS for example 2\n",
        "\n",
        "def IWLS(X,Y,beta_init,maxiter,epsilon):\n",
        "    res = {'FM': None, 'SV': None, 'betas': None}\n",
        "    # Fisher-scoring algorithm\n",
        "    i = 1     # first iteration\n",
        "\n",
        "    beta_i = beta_init\n",
        "    \n",
        "    while i <= maxiter:\n",
        "        W = calc_W_inv(X,beta_i)\n",
        "        Z = calc_Z(X,Y,beta_i)\n",
        "        beta_pred = beta_i\n",
        "        beta_i = np.linalg.solve(X.T@W@X, X.T@W@Z)\n",
        "        diff = np.max(np.abs(beta_i - beta_pred))\n",
        "        if diff < epsilon:\n",
        "            break\n",
        "        W = calc_W_inv(X, beta_i)\n",
        "        Z = calc_Z(X, Y, beta_i)\n",
        "\n",
        "        res['SV'] = X.T@W@Z\n",
        "        res['FM'] = X.T@W@X\n",
        "        res['betas'] = np.linalg.solve(X.T@W@X, X.T@W@Z)\n",
        "        i += 1\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VDw0-mqZF7x"
      },
      "outputs": [],
      "source": [
        "# Estimation of betas\n",
        "result1 = IWLS(X,Y,np.ones(2),100,10^(-6))\n",
        "print(f'Estimation of parameters: {result1[\"betas\"]}')      # Estimation of parameters\n",
        "print(f'Estimated Fisher information matrix: {result1[\"FM\"]}')        # Estimated Fisher information matrix\n",
        "print(f'Estimated covariance matrix: {np.linalg.inv(result1[\"FM\"])}')  # Estimated covariance matrix  = Inverse of estimated Fisher information matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEUlAqmFH_mB"
      },
      "source": [
        "Comparison of our custom solution with the built in glm function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E-UbtQQXALw"
      },
      "outputs": [],
      "source": [
        "print(model.summary())\n",
        "\n",
        "# the unscaled (dispersion = 1) estimated covariance matrix of the estimated coefficients.\n",
        "FIM1 = model.cov_params()\n",
        "print(f'estimated covariance matrix {FIM1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMMvkPUTOSqI"
      },
      "outputs": [],
      "source": [
        "# to find out what params has `model` object\n",
        "for attr in dir(model):\n",
        "    if not attr.startswith('_'):\n",
        "        print(attr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7vo_sJaOFiL"
      },
      "source": [
        "Asymptotics:\n",
        "\n",
        "* $ (\\hat{\\beta} - \\beta) \\sim N_{p}(0, I^{-1}(\\beta))$ \n",
        "* Estimated Fisher information matrix  $\\hat{I}(\\hat{\\beta}) = (X^T \\hat{W} X)$  matrix.\n",
        "*  Estimated covariance matrix $\\hat{V} (\\hat{\\beta}) = (X^T \\hat{W} X)^{-1}$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB52Ef03Z7uO"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "repet = 50\n",
        "n_observ = np.array([1,2,5,10,100, 500])\n",
        "betas_hat = np.zeros((6, repet, 2))\n",
        "\n",
        "for _, i in enumerate(n_observ):\n",
        "    for j in range(repet):\n",
        "        X1 = np.ones((n*i,))\n",
        "        X2 = np.array([i for i in range(1, n+1)]*i)\n",
        "        X  = np.vstack([X1, np.log(X2)]).T\n",
        "        beta = np.array([0.9, 1.3]) # Regression coefficients\n",
        "        lamdas = np.exp(X @ beta) # Means\n",
        "        Y = np.random.poisson(lamdas, n*i)\n",
        "        betas_hat[_, j] = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit().params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkafuLnXZ7xG"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in range(len(n_observ)):\n",
        "    print(f\"Number of observations: {n_observ[i]*n}\")\n",
        "    print(np.cov((betas_hat[i] - beta).T))\n",
        "    print(np.mean(betas_hat[i] - beta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TjcOg79UPRM"
      },
      "source": [
        "## Hypothesis testing\n",
        "\n",
        "Use the model from the beginning again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rwWB0Grrmnt"
      },
      "outputs": [],
      "source": [
        "n  = 20\n",
        "m  = 2\n",
        "\n",
        "X1 = np.ones((n*m,))\n",
        "X2 = np.array([i for i in range(1, n+1)]*m)\n",
        "X  = np.vstack([X1, np.log(X2)]).T\n",
        "beta = np.array([0.9, 1.3]) # Regression coefficients\n",
        "lamdas = np.exp(X @ beta) # Means\n",
        "Y = np.random.poisson(lamdas, n*m)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2opFFdr0UfhS"
      },
      "outputs": [],
      "source": [
        "model = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
        "print(model.summary())\n",
        "\n",
        "# the unscaled (dispersion = 1) estimated covariance matrix of the estimated coefficients.\n",
        "FIM1 = model.cov_params()\n",
        "print(f'estimated covariance matrix {FIM1}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR3DTTTWV94T"
      },
      "source": [
        "Calculation of Z value\n",
        " $$Z_i = \\frac{\\hat{\\beta_i}}{(I^{-1}(\\hat{\\beta_i}))_{ii}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lv8guvybUK-E"
      },
      "outputs": [],
      "source": [
        "# Testing statistics from summary table\n",
        "model.summary()\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNjECz1FNw_c"
      },
      "outputs": [],
      "source": [
        "# By definition\n",
        "\n",
        "z_stat = model.params / np.sqrt(np.diag(model.cov_params()))\n",
        "print(z_stat)\n",
        "z_stat == model.tvalues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mHfejdWULDh"
      },
      "outputs": [],
      "source": [
        "# p-values of the test\n",
        "p_val = 2*scipy.stats.norm.sf(z_stat, loc=0, scale=1)\n",
        "print(f'pval: {p_val}')\n",
        "p_val == model.pvalues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GdfbeqdYOIv"
      },
      "outputs": [],
      "source": [
        "### 100(1-alpha) confidence interval\n",
        "alpha = 0.05\n",
        "u = scipy.stats.norm.ppf(1-alpha/2,0,1)\n",
        "CI_LB = model.params[1] - u * np.sqrt(np.diag(model.cov_params())[1])\n",
        "CI_UB = model.params[1] + u * np.sqrt(np.diag(model.cov_params())[1])\n",
        "\n",
        "print(f\"2.5% CI = {CI_LB},ESTIM = {model.params[1]}, 97.5% CI = {CI_UB}\")\n",
        "\n",
        "\n",
        "# built in function\n",
        "print(model.conf_int())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkhFJFXceHjn"
      },
      "source": [
        "Question:\n",
        "\n",
        "* Compare hypothesis testing in LM vs. GLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwXaIg0peQee"
      },
      "source": [
        "# Deviance\n",
        "\n",
        "Deviance is a measure of goodness of fit of a GLM. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjNUyZoZeStY"
      },
      "source": [
        "Log-likelihood of the saturated model is the highest possible one with given data, $\\tilde{\\mu}_i = y_i$ and $\\tilde{\\theta_i} = \\theta(y) = (b')^{-1}(y_i)$.\n",
        "$$l(\\tilde{\\mu},\\phi;y)=\\sum_{i=1}^{n}\\frac{y_{i}\\tilde{\\theta}_{i}-b(\\tilde{\\theta}_{i})}{a_{i}(\\phi)}+\\sum_{i=1}^{n}c(y_i,\\phi)$$\n",
        "\n",
        "Scale deviance statistics:\n",
        "$${S(y,\\hat{\\mu},\\phi)}=2\\left[l(\\tilde{\\mu},\\phi;y)-l(\\hat{\\mu},\\phi;y)\\right]\n",
        "=2\\sum_{i=1}^{n}\\frac{y_{i}(\\tilde{\\theta}_{i}-\\hat{\\theta}_{i})\n",
        "-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)}{a_{i}(\\phi)}.\n",
        "$$\n",
        "\n",
        "Deviance:\n",
        "Let $a_{i}(\\phi)=a_{i}\\phi$, then\n",
        "$$S(y,\\hat{\\mu},\\phi)=\\frac{D(y,\\hat{\\mu})}{\\phi},\n",
        "$$\n",
        "and\n",
        "$$\n",
        "D(y,\\hat{\\mu})=2\\sum_{i=1}^{n}\\frac{y_{i}(\\tilde{\\theta}_{i}-\\hat{\\theta}_{i})\n",
        "-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)}{a_{i}}\n",
        "$$\n",
        "\n",
        "### Comparison of two models\n",
        "\n",
        "Assume model $D_0$ with $p_0$ paramters and its sub-model $D_1$ with $p_1$ parameters, then\n",
        "$$ \\frac{1}{\\phi} (D_0 - D_1) \\sim \\chi(p_0 - p_1) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLxMlbIKeTe5"
      },
      "source": [
        "Question:\n",
        "* Can we take deviance as a measure of the model quality?\n",
        "* Can we use deviance as a measure of the saturated model quality?\n",
        "* Complete the sentence: Compare two GLMs with deviance is like compare two LMs with ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PVvXp_SpDUx"
      },
      "outputs": [],
      "source": [
        "# Add random variable to the previous model \n",
        "Z = scipy.stats.uniform.rvs(loc=0, scale=1, size=n*m)\n",
        "model_0 = sm.GLM(endog=Y, exog=np.hstack([X, Z[:, None]]), family=sm.families.Poisson()).fit()\n",
        "model_0.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O24NMRTPjoA"
      },
      "outputs": [],
      "source": [
        "# Proposed model\n",
        "m1 = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson())\n",
        "model_1 = m1.fit()\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbtdZzD6Pjx6"
      },
      "outputs": [],
      "source": [
        "# Null model\n",
        "\n",
        "model_n = sm.GLM(endog=Y, exog=X[:, 0], family=sm.families.Poisson()).fit()\n",
        "model_n.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "508GBQM_Pj5L"
      },
      "outputs": [],
      "source": [
        "# Saturated model CANNOT BY OBTAINED BY STATSMODELS BY DEFAULT 'CAUSE THEY PREVENT ZERO DIVISION\n",
        "\n",
        "# BUT MY WORKAROUND WHICH PROBABLY WILL NOT WORK IN COLAB AS WE DO NOT HAVE ACCESS TO MODULES IS\n",
        "# TO COMMENT OUT ROWS 1227-1229 IN MOST RECENT VERSION \n",
        "# (SEE https://github.com/statsmodels/statsmodels/blob/main/statsmodels/genmod/generalized_linear_model.py)\n",
        "\n",
        "I = np.diag(np.ones((m*n,)))\n",
        "\n",
        "\n",
        "model_s = sm.GLM(endog=Y, exog=I, family=sm.families.Poisson()).fit()\n",
        "print(model_s.summary())\n",
        "print(f'Residual deviance is: {model_s.deviance}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWfxVEHguydO"
      },
      "source": [
        "For Poisson model:\n",
        "$$D = 2 \\sum_{i=1}^n y_i log( \\frac{y_i}{\\hat{\\mu_i}})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Dm5NQ5Jr509"
      },
      "outputs": [],
      "source": [
        "mu_est_0 = model_0.predict()\n",
        "mu_est_1 = model_1.predict()\n",
        "\n",
        "Dev_0 = 2*np.sum(Y*np.log(Y/mu_est_0))\n",
        "print(Dev_0)\n",
        "Dev_1 = 2*np.sum(Y*np.log(Y/mu_est_1))\n",
        "print(Dev_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNbCpDS0OSqN"
      },
      "outputs": [],
      "source": [
        "anova = Anova()\n",
        "anova(model_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9SuGMWFwhDM"
      },
      "source": [
        "## Anova testing \n",
        "from anova.glm?\n",
        "\n",
        "The table will optionally contain test statistics (and P values) comparing the reduction in deviance for the row to the residuals. For models with known dispersion (e.g., binomial and Poisson fits) the chi-squared test is most appropriate, and for those with dispersion estimated by moments (e.g., gaussian, quasibinomial and quasipoisson fits) the F test is most appropriate. \n",
        "\n",
        "Mallows' Cp statistic is the residual deviance plus twice the estimate of $sigma^2$ times the residual degrees of freedom, which is closely related to AIC (and a multiple of it if the dispersion is known). You can also choose \"LRT\" and \"Rao\" for likelihood ratio tests and Rao's efficient score test. The former is synonymous with \"Chisq\" (although both have an asymptotic chi-square distribution). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8MegJJTsqvK"
      },
      "outputs": [],
      "source": [
        "display(anova(model_1))\n",
        "display(anova(model_1, test = \"Cp\"))\n",
        "display(anova(model_1, test = \"Chisq\"))\n",
        "\n",
        "display(anova(model_1, model_0, test = \"Rao\"))  # TODO Needs correct formula \n",
        "print(anova(model_1, model_0, test = \"LRT\"))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UchWeYjOxI7X"
      },
      "outputs": [],
      "source": [
        "# p-value of deviance tst\n",
        "# H0: model fit data\n",
        "p_dev = scipy.stats.chi2.sf(model_1.deviance, df=model_1.df_resid)\n",
        "\n",
        "print(p_dev)\n",
        "\n",
        "# critical value\n",
        "C_val = scipy.stats.chi2.isf(0.05, model_1.df_resid)\n",
        "print(C_val)\n",
        "\n",
        "print(model_1.summary())\n",
        "\n",
        "display(anova(model_1,model_s, test = \"LRT\"))   # saturated vs. final model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4Ek6Y464bE"
      },
      "source": [
        "## Rao statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrTIUoUKUKDg"
      },
      "outputs": [],
      "source": [
        "######## Rao score statistics (for Poisson GLM)\n",
        "\n",
        "#score = model_1.resid_response / model_1.model.family.variance(model_1.predict())\n",
        "#rao = score.T @  np.diag(model_1.model.family.variance(model_1.predict())) @ score\n",
        "# model_1.resid_pearson @ model_1.resid_pearson.T \n",
        "\n",
        "rao = np.sum((Y-model_1.predict())**2/model_1.predict())\n",
        "\n",
        "print(f'rao score statistic: {rao}')\n",
        "\n",
        "# p-hodnota testu adekvatnosti modelu (pomoci Raovy statistiky)\n",
        "# H0: model dobre popisuje data\n",
        "\n",
        "print(f'p-val of rao test: {scipy.stats.chi2.sf(rao, df=model_1.df_resid)}')\n",
        "\n",
        "######  pomoci saturovaneho modelu\n",
        "\n",
        "anova(model_1,model_s, test = \"Rao\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAmB4PDZJKEl"
      },
      "source": [
        "# Your turn:\n",
        "1. Generate data with followings parameters\n",
        " * $Y \\sim Poi(\\mu_i)$, where $E[Y_i] = \\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} = x_i^T \\beta \\  \\Rightarrow \\ q(\\mu_i) = \\mu_i =  x_i^T \\beta  = \\eta_i$\n",
        "* $X_{i1} \\sim N(50,10)$\n",
        "* $X_{i2} \\sim U(10,60)$\n",
        "* $X_{i3} \\sim Ber(0.45)$\n",
        "* $n = 40$\n",
        "2. Compute $\\hat{\\mu_i}$  for saturated, null,\"full\",\"best\" models.\n",
        "3. Compute Deviance, Rao, Wald statistics for your model and compare final model with the saturated and \"full\" ones.\n",
        "4. Generate 100x data for  $n \\in \\{20,40,60,80,100 \\}$ and plot $(\\hat{\\beta_i} -\\beta_i)$ vs. $(n)$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O60Qhn1rV7Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H9KmDWkOSqP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}